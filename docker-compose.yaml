services:
  fast_app:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./:/app
    ports:
      - 80:80
    environment:
      - TRITON_SERVER_URL=triton:8000
    depends_on:
      - triton
    networks:
      - inference_network

  triton:
    image: nvcr.io/nvidia/tritonserver:24.09-py3
    command: tritonserver --model-repository=/models --strict-model-config=false --strict-readiness=false --http-port=8000 --grpc-port=8001 --metrics-port=8002 --allow-http=true --allow-grpc=true --allow-metrics=true --http-thread-count=4
    ports:
      - "0.0.0.0:8000:8000"   # HTTP endpoint - explicitly bound to all interfaces
      - "0.0.0.0:8001:8001"   # gRPC endpoint - explicitly bound to all interfaces
      - "0.0.0.0:8002:8002"   # Metrics endpoint - explicitly bound to all interfaces
    volumes:
      - ./models:/models
    environment:
      - TZ=UTC
    networks:
      - inference_network

networks:
  inference_network:
    driver: bridge